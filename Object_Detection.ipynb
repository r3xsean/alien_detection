{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1QCU_dCR0ozI8j6X2btEDCsaUk5p_b1uw","timestamp":1690562459747},{"file_id":"12BNAgMHzQ5YgaijYxvVKWkGUtNSq1In3","timestamp":1636485335078},{"file_id":"1YWjDuJgdIvK1yenD3Wmb3_JARuPOuKht","timestamp":1615417926325}],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"pjfRnVN12JWF"},"source":["# Importing our libraries... *"]},{"cell_type":"code","metadata":{"id":"R1Fl0K9TVJ50","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690608447766,"user_tz":-480,"elapsed":3304,"user":{"displayName":"r3xSean","userId":"17171356728383377491"}},"outputId":"cdbfa532-e838-40fc-e980-121e0468ec42"},"source":["import os\n","\n","import tensorflow as tf\n","\n","import pandas as pd\n","import glob\n","import xml.etree.ElementTree as ET\n","\n","print(\"Finished!\")\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Finished!\n"]}]},{"cell_type":"markdown","metadata":{"id":"92GABWQa1eYT"},"source":["# Creating ***customTF2***, and inside that, ***training*** and ***data*** folders in google drive\n"]},{"cell_type":"markdown","source":["# How we trained our own model (COLLAPSE IF YOU WANT TO USE TRAINED)"],"metadata":{"id":"L2eVPpt3fC-y"}},{"cell_type":"markdown","metadata":{"id":"ca4Hv2sT4lt-"},"source":["## Upload the image files\n","folder named ***images*** for dataset images and another folder named ***annotations*** for its corresponding xml files\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","source":["## Labelling image files to retrieve their XML\n","\n","We will have to run this outside of the colab!"],"metadata":{"id":"uvovYe67dSta"}},{"cell_type":"markdown","source":["### 1) Download [OpenLabelling](https://github.com/techzizou/OpenLabeling) and unzip\n","\n","It's a python script which allows us to label objects within our images with classes for use in training.\n","\n","After unzipping, navigate to the ***OpenLabeling-master*** folder"],"metadata":{"id":"J-LjMHMdewxF"}},{"cell_type":"markdown","source":["### 2) Make sure the modules in ***requirement.txt*** are installed\n","\n","\n","Run the following after navigating to ***OpenLabeling-master*** folder in the command prompt\n","```\n","pip install -r requirements.txt\n","```\n","\n"],"metadata":{"id":"sflbtJCHe5pq"}},{"cell_type":"markdown","source":["### 3) Navigate to ***main*** and open up class_list.txt\n","\n","Go line by line typing out each class, for example,\n","```\n","Alien\n","Human\n","```"],"metadata":{"id":"R-0T6yEkiJOu"}},{"cell_type":"markdown","source":["### 4) Put all your \".JPG\" images inside the ***input*** folder\n","\n","Remember, it has to end with \".jpg\", or it will not work."],"metadata":{"id":"TYFAHRz8ipNb"}},{"cell_type":"markdown","source":["### 5) Run the main.py script\n","\n","This will create the output folder and open the GUI for labeling."],"metadata":{"id":"skTOhEuiGoVu"}},{"cell_type":"markdown","source":["### 6) Start labeling!\n","\n","Once you have labeled them all, you can copy the xml files over to another place."],"metadata":{"id":"SVpz2oXUHqne"}},{"cell_type":"markdown","metadata":{"id":"rHnTmrSwNg6S"},"source":["## Upload the ***generate_tfrecord.py*** file to the ***customTF2*** folder on your drive.**bold text**\n","\n","Found [here](https://github.com/techzizou/Train-Object-Detection-Model-TF-2.x)"]},{"cell_type":"code","metadata":{"id":"RhZoiRBoqnju","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690608493097,"user_tz":-480,"elapsed":16116,"user":{"displayName":"r3xSean","userId":"17171356728383377491"}},"outputId":"e631862b-539c-45ae-d31f-1582f217744c"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","# this creates a symbolic link so that now the path /content/gdrive/My\\ Drive/ is equal to /mydrive\n","!ln -s /content/gdrive/My\\ Drive/ /mydrive\n","!ls /mydrive"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"," 20190329_151514.jpg\n"," 20190329_151545.jpg\n"," 20190329_151614.jpg\n","'Aztler GSHeet D&D.gsheet'\n"," Classroom\n"," CoinbaseWalletBackups\n","'Colab Notebooks'\n","'Copy of 30 Days to Better Habits: Examples Database.gsheet'\n","'Copy of ER - Weapon Usability v0.3.1.gsheet'\n","'Copy of Gestalt Avrae Readable Gsheet.gsheet'\n","'Copy of GSheet v2.1 (1).gsheet'\n","'Copy of GSheet v2.1 (2).gsheet'\n","'Copy of GSheet v2.1.gsheet'\n","'Copy of Item Sheets.gsheet'\n","'Copy of OSSU CS Timeline .gsheet'\n","'Copy of PHB.pdf'\n","'Copy of WorldFoodDay.gslides'\n"," customTF2\n","'D&D Discord Server Timetables.gsheet'\n","'D&D EA.gsheet'\n","'Download2021.12.05.23.45.36_New IGCSE Admission Form.pdf.PDF'\n","'Editable Fix Character Values Buttons.gscript'\n"," eroan.gsheet\n"," first-order-motion-model\n","'GIIS SG (PG) Grade 10 English Language Worksheet 2023-24 April-May.gdoc'\n"," GP\n","'GSheet v2.1.gsheet'\n","'How to play D&D.gdoc'\n","\"JoJo's Bizarre Adventure_ Stardust Crusaders OST - Stardust Crusaders.mp3\"\n","'Life Level.gsheet'\n","'Life Timetable.gsheet'\n","'LudicSavant and AureusFulgen'\\''s DPR Calculator (v2.51).gsheet'\n"," memes\n"," meta2_final.gsheet\n","'PROPOSED  SPACE BUDGET.gsheet'\n"," Resume.gdoc\n","'Sample Essay.gdoc'\n"," school\n"," sensou.gdoc\n"," svnwndrsfthwrld.gslides\n"," Timetable.gsheet\n","'Trainer Template.gsheet'\n","'Untitled document (1).gdoc'\n","'Untitled document (2).gdoc'\n","'Untitled document (3).gdoc'\n","'Untitled document.gdoc'\n","'Untitled presentation (1).gslides'\n","'Untitled presentation.gslides'\n","'Untitled spreadsheet (1).gsheet'\n","'Untitled spreadsheet (2).gsheet'\n","'Untitled spreadsheet.gsheet'\n","'Workout Log (BW).gsheet'\n","'WorldFoodDay (1).gslides'\n"," WorldFoodDay.gslides\n"," WorldFoodDay.pptx\n"]}]},{"cell_type":"code","source":["# clone the tensorflow models on the colab cloud vm\n","!git clone --q https://github.com/tensorflow/models.git\n","\n","#navigate to /models/research folder to compile protos\n","%cd models/research\n","\n","# Compile protos.\n","!protoc object_detection/protos/*.proto --python_out=.\n","\n","# Install TensorFlow Object Detection API.\n","!cp object_detection/packages/tf2/setup.py .\n","!python -m pip install .\n"],"metadata":{"id":"hM2UMGL5SPWF"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"St1r_0-w9jqI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690608720842,"user_tz":-480,"elapsed":56547,"user":{"displayName":"r3xSean","userId":"17171356728383377491"}},"outputId":"f7e42abe-3edd-464e-a457-52554d489280"},"source":["# testing the model builder\n","!python object_detection/builders/model_builder_tf2_test.py"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-07-29 05:31:08.712494: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","/usr/local/lib/python3.10/dist-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/usr/local/lib/python3.10/dist-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n","caused by: ['/usr/local/lib/python3.10/dist-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6Status12empty_stringB5cxx11Ev']\n","  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n","/usr/local/lib/python3.10/dist-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/usr/local/lib/python3.10/dist-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n","caused by: ['/usr/local/lib/python3.10/dist-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZNK10tensorflow4data11DatasetBase8FinalizeEPNS_15OpKernelContextESt8functionIFN3tsl8StatusOrISt10unique_ptrIS1_NS5_4core15RefCountDeleterEEEEvEE']\n","  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","Running tests under Python 3.10.6: /usr/bin/python3\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n","2023-07-29 05:31:15.156072: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","WARNING:tensorflow:`tf.keras.layers.experimental.SyncBatchNormalization` endpoint is deprecated and will be removed in a future release. Please use `tf.keras.layers.BatchNormalization` with parameter `synchronized` set to True.\n","W0729 05:31:15.196168 140213217529856 batch_normalization.py:1531] `tf.keras.layers.experimental.SyncBatchNormalization` endpoint is deprecated and will be removed in a future release. Please use `tf.keras.layers.BatchNormalization` with parameter `synchronized` set to True.\n","W0729 05:31:15.858140 140213217529856 model_builder.py:1112] Building experimental DeepMAC meta-arch. Some features may be omitted.\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 2.65s\n","I0729 05:31:16.165662 140213217529856 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 2.65s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.6s\n","I0729 05:31:16.765320 140213217529856 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.6s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.31s\n","I0729 05:31:17.078849 140213217529856 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.31s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.46s\n","I0729 05:31:17.535385 140213217529856 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.46s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.12s\n","I0729 05:31:19.652037 140213217529856 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.12s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n","[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n","I0729 05:31:19.658622 140213217529856 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\n","I0729 05:31:19.685032 140213217529856 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n","I0729 05:31:19.702470 140213217529856 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n","I0729 05:31:19.721204 140213217529856 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.11s\n","I0729 05:31:19.827571 140213217529856 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.11s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.11s\n","I0729 05:31:19.937590 140213217529856 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.11s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.11s\n","I0729 05:31:20.045024 140213217529856 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.11s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.11s\n","I0729 05:31:20.157479 140213217529856 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.11s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.11s\n","I0729 05:31:20.263806 140213217529856 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.11s\n","[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n","[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n","I0729 05:31:20.295328 140213217529856 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n","[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n","[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n","I0729 05:31:20.503073 140213217529856 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b0\n","I0729 05:31:20.503233 140213217529856 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 64\n","I0729 05:31:20.503321 140213217529856 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 3\n","I0729 05:31:20.505937 140213217529856 efficientnet_model.py:143] round_filter input=32 output=32\n","I0729 05:31:20.536021 140213217529856 efficientnet_model.py:143] round_filter input=32 output=32\n","I0729 05:31:20.536147 140213217529856 efficientnet_model.py:143] round_filter input=16 output=16\n","I0729 05:31:20.616245 140213217529856 efficientnet_model.py:143] round_filter input=16 output=16\n","I0729 05:31:20.616394 140213217529856 efficientnet_model.py:143] round_filter input=24 output=24\n","I0729 05:31:20.818091 140213217529856 efficientnet_model.py:143] round_filter input=24 output=24\n","I0729 05:31:20.818246 140213217529856 efficientnet_model.py:143] round_filter input=40 output=40\n","I0729 05:31:21.010845 140213217529856 efficientnet_model.py:143] round_filter input=40 output=40\n","I0729 05:31:21.011010 140213217529856 efficientnet_model.py:143] round_filter input=80 output=80\n","I0729 05:31:21.297964 140213217529856 efficientnet_model.py:143] round_filter input=80 output=80\n","I0729 05:31:21.298133 140213217529856 efficientnet_model.py:143] round_filter input=112 output=112\n","I0729 05:31:21.589374 140213217529856 efficientnet_model.py:143] round_filter input=112 output=112\n","I0729 05:31:21.589522 140213217529856 efficientnet_model.py:143] round_filter input=192 output=192\n","I0729 05:31:21.964218 140213217529856 efficientnet_model.py:143] round_filter input=192 output=192\n","I0729 05:31:21.964394 140213217529856 efficientnet_model.py:143] round_filter input=320 output=320\n","I0729 05:31:22.053325 140213217529856 efficientnet_model.py:143] round_filter input=1280 output=1280\n","I0729 05:31:22.103723 140213217529856 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0729 05:31:22.158350 140213217529856 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b1\n","I0729 05:31:22.158481 140213217529856 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 88\n","I0729 05:31:22.158555 140213217529856 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 4\n","I0729 05:31:22.160383 140213217529856 efficientnet_model.py:143] round_filter input=32 output=32\n","I0729 05:31:22.178432 140213217529856 efficientnet_model.py:143] round_filter input=32 output=32\n","I0729 05:31:22.178547 140213217529856 efficientnet_model.py:143] round_filter input=16 output=16\n","I0729 05:31:22.329818 140213217529856 efficientnet_model.py:143] round_filter input=16 output=16\n","I0729 05:31:22.329958 140213217529856 efficientnet_model.py:143] round_filter input=24 output=24\n","I0729 05:31:22.609565 140213217529856 efficientnet_model.py:143] round_filter input=24 output=24\n","I0729 05:31:22.609735 140213217529856 efficientnet_model.py:143] round_filter input=40 output=40\n","I0729 05:31:23.163629 140213217529856 efficientnet_model.py:143] round_filter input=40 output=40\n","I0729 05:31:23.163820 140213217529856 efficientnet_model.py:143] round_filter input=80 output=80\n","I0729 05:31:23.718198 140213217529856 efficientnet_model.py:143] round_filter input=80 output=80\n","I0729 05:31:23.718431 140213217529856 efficientnet_model.py:143] round_filter input=112 output=112\n","I0729 05:31:24.246916 140213217529856 efficientnet_model.py:143] round_filter input=112 output=112\n","I0729 05:31:24.247098 140213217529856 efficientnet_model.py:143] round_filter input=192 output=192\n","I0729 05:31:24.882699 140213217529856 efficientnet_model.py:143] round_filter input=192 output=192\n","I0729 05:31:24.882925 140213217529856 efficientnet_model.py:143] round_filter input=320 output=320\n","I0729 05:31:25.139652 140213217529856 efficientnet_model.py:143] round_filter input=1280 output=1280\n","I0729 05:31:25.185992 140213217529856 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0729 05:31:25.293314 140213217529856 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b2\n","I0729 05:31:25.293483 140213217529856 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 112\n","I0729 05:31:25.293554 140213217529856 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 5\n","I0729 05:31:25.296482 140213217529856 efficientnet_model.py:143] round_filter input=32 output=32\n","I0729 05:31:25.323073 140213217529856 efficientnet_model.py:143] round_filter input=32 output=32\n","I0729 05:31:25.323208 140213217529856 efficientnet_model.py:143] round_filter input=16 output=16\n","I0729 05:31:25.521737 140213217529856 efficientnet_model.py:143] round_filter input=16 output=16\n","I0729 05:31:25.521906 140213217529856 efficientnet_model.py:143] round_filter input=24 output=24\n","I0729 05:31:25.908100 140213217529856 efficientnet_model.py:143] round_filter input=24 output=24\n","I0729 05:31:25.908285 140213217529856 efficientnet_model.py:143] round_filter input=40 output=48\n","I0729 05:31:26.309067 140213217529856 efficientnet_model.py:143] round_filter input=40 output=48\n","I0729 05:31:26.309254 140213217529856 efficientnet_model.py:143] round_filter input=80 output=88\n","I0729 05:31:26.867198 140213217529856 efficientnet_model.py:143] round_filter input=80 output=88\n","I0729 05:31:26.867411 140213217529856 efficientnet_model.py:143] round_filter input=112 output=120\n","I0729 05:31:27.540617 140213217529856 efficientnet_model.py:143] round_filter input=112 output=120\n","I0729 05:31:27.540828 140213217529856 efficientnet_model.py:143] round_filter input=192 output=208\n","I0729 05:31:29.368490 140213217529856 efficientnet_model.py:143] round_filter input=192 output=208\n","I0729 05:31:29.368710 140213217529856 efficientnet_model.py:143] round_filter input=320 output=352\n","I0729 05:31:30.130688 140213217529856 efficientnet_model.py:143] round_filter input=1280 output=1408\n","I0729 05:31:30.304889 140213217529856 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0729 05:31:30.655952 140213217529856 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b3\n","I0729 05:31:30.658403 140213217529856 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 160\n","I0729 05:31:30.658568 140213217529856 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 6\n","I0729 05:31:30.661719 140213217529856 efficientnet_model.py:143] round_filter input=32 output=40\n","I0729 05:31:30.772174 140213217529856 efficientnet_model.py:143] round_filter input=32 output=40\n","I0729 05:31:30.773967 140213217529856 efficientnet_model.py:143] round_filter input=16 output=24\n","I0729 05:31:31.366065 140213217529856 efficientnet_model.py:143] round_filter input=16 output=24\n","I0729 05:31:31.366407 140213217529856 efficientnet_model.py:143] round_filter input=24 output=32\n","I0729 05:31:32.467902 140213217529856 efficientnet_model.py:143] round_filter input=24 output=32\n","I0729 05:31:32.468111 140213217529856 efficientnet_model.py:143] round_filter input=40 output=48\n","I0729 05:31:33.537135 140213217529856 efficientnet_model.py:143] round_filter input=40 output=48\n","I0729 05:31:33.540543 140213217529856 efficientnet_model.py:143] round_filter input=80 output=96\n","I0729 05:31:34.349893 140213217529856 efficientnet_model.py:143] round_filter input=80 output=96\n","I0729 05:31:34.350126 140213217529856 efficientnet_model.py:143] round_filter input=112 output=136\n","I0729 05:31:35.080879 140213217529856 efficientnet_model.py:143] round_filter input=112 output=136\n","I0729 05:31:35.081085 140213217529856 efficientnet_model.py:143] round_filter input=192 output=232\n","I0729 05:31:35.934977 140213217529856 efficientnet_model.py:143] round_filter input=192 output=232\n","I0729 05:31:35.935190 140213217529856 efficientnet_model.py:143] round_filter input=320 output=384\n","I0729 05:31:36.238793 140213217529856 efficientnet_model.py:143] round_filter input=1280 output=1536\n","I0729 05:31:36.297559 140213217529856 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0729 05:31:36.411362 140213217529856 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b4\n","I0729 05:31:36.411556 140213217529856 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 224\n","I0729 05:31:36.411638 140213217529856 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 7\n","I0729 05:31:36.414757 140213217529856 efficientnet_model.py:143] round_filter input=32 output=48\n","I0729 05:31:36.445426 140213217529856 efficientnet_model.py:143] round_filter input=32 output=48\n","I0729 05:31:36.445594 140213217529856 efficientnet_model.py:143] round_filter input=16 output=24\n","I0729 05:31:36.604729 140213217529856 efficientnet_model.py:143] round_filter input=16 output=24\n","I0729 05:31:36.604883 140213217529856 efficientnet_model.py:143] round_filter input=24 output=32\n","I0729 05:31:36.967984 140213217529856 efficientnet_model.py:143] round_filter input=24 output=32\n","I0729 05:31:36.968145 140213217529856 efficientnet_model.py:143] round_filter input=40 output=56\n","I0729 05:31:37.621776 140213217529856 efficientnet_model.py:143] round_filter input=40 output=56\n","I0729 05:31:37.621940 140213217529856 efficientnet_model.py:143] round_filter input=80 output=112\n","I0729 05:31:38.189151 140213217529856 efficientnet_model.py:143] round_filter input=80 output=112\n","I0729 05:31:38.189322 140213217529856 efficientnet_model.py:143] round_filter input=112 output=160\n","I0729 05:31:38.759599 140213217529856 efficientnet_model.py:143] round_filter input=112 output=160\n","I0729 05:31:38.759757 140213217529856 efficientnet_model.py:143] round_filter input=192 output=272\n","I0729 05:31:39.527596 140213217529856 efficientnet_model.py:143] round_filter input=192 output=272\n","I0729 05:31:39.527764 140213217529856 efficientnet_model.py:143] round_filter input=320 output=448\n","I0729 05:31:39.722814 140213217529856 efficientnet_model.py:143] round_filter input=1280 output=1792\n","I0729 05:31:39.761067 140213217529856 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0729 05:31:39.851480 140213217529856 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b5\n","I0729 05:31:39.851629 140213217529856 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 288\n","I0729 05:31:39.851693 140213217529856 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 7\n","I0729 05:31:39.853770 140213217529856 efficientnet_model.py:143] round_filter input=32 output=48\n","I0729 05:31:39.872162 140213217529856 efficientnet_model.py:143] round_filter input=32 output=48\n","I0729 05:31:39.872283 140213217529856 efficientnet_model.py:143] round_filter input=16 output=24\n","I0729 05:31:40.086115 140213217529856 efficientnet_model.py:143] round_filter input=16 output=24\n","I0729 05:31:40.086279 140213217529856 efficientnet_model.py:143] round_filter input=24 output=40\n","I0729 05:31:40.564607 140213217529856 efficientnet_model.py:143] round_filter input=24 output=40\n","I0729 05:31:40.564807 140213217529856 efficientnet_model.py:143] round_filter input=40 output=64\n","I0729 05:31:41.024779 140213217529856 efficientnet_model.py:143] round_filter input=40 output=64\n","I0729 05:31:41.024946 140213217529856 efficientnet_model.py:143] round_filter input=80 output=128\n","I0729 05:31:41.683612 140213217529856 efficientnet_model.py:143] round_filter input=80 output=128\n","I0729 05:31:41.683783 140213217529856 efficientnet_model.py:143] round_filter input=112 output=176\n","I0729 05:31:42.343419 140213217529856 efficientnet_model.py:143] round_filter input=112 output=176\n","I0729 05:31:42.343582 140213217529856 efficientnet_model.py:143] round_filter input=192 output=304\n","I0729 05:31:43.158927 140213217529856 efficientnet_model.py:143] round_filter input=192 output=304\n","I0729 05:31:43.159093 140213217529856 efficientnet_model.py:143] round_filter input=320 output=512\n","I0729 05:31:43.451556 140213217529856 efficientnet_model.py:143] round_filter input=1280 output=2048\n","I0729 05:31:43.490061 140213217529856 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0729 05:31:43.579779 140213217529856 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b6\n","I0729 05:31:43.579916 140213217529856 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 384\n","I0729 05:31:43.579988 140213217529856 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 8\n","I0729 05:31:43.581817 140213217529856 efficientnet_model.py:143] round_filter input=32 output=56\n","I0729 05:31:43.602828 140213217529856 efficientnet_model.py:143] round_filter input=32 output=56\n","I0729 05:31:43.602939 140213217529856 efficientnet_model.py:143] round_filter input=16 output=32\n","I0729 05:31:43.829527 140213217529856 efficientnet_model.py:143] round_filter input=16 output=32\n","I0729 05:31:43.829712 140213217529856 efficientnet_model.py:143] round_filter input=24 output=40\n","I0729 05:31:44.380206 140213217529856 efficientnet_model.py:143] round_filter input=24 output=40\n","I0729 05:31:44.380375 140213217529856 efficientnet_model.py:143] round_filter input=40 output=72\n","I0729 05:31:44.929153 140213217529856 efficientnet_model.py:143] round_filter input=40 output=72\n","I0729 05:31:44.929330 140213217529856 efficientnet_model.py:143] round_filter input=80 output=144\n","I0729 05:31:45.948411 140213217529856 efficientnet_model.py:143] round_filter input=80 output=144\n","I0729 05:31:45.948570 140213217529856 efficientnet_model.py:143] round_filter input=112 output=200\n","I0729 05:31:46.821762 140213217529856 efficientnet_model.py:143] round_filter input=112 output=200\n","I0729 05:31:46.821956 140213217529856 efficientnet_model.py:143] round_filter input=192 output=344\n","I0729 05:31:48.366834 140213217529856 efficientnet_model.py:143] round_filter input=192 output=344\n","I0729 05:31:48.367032 140213217529856 efficientnet_model.py:143] round_filter input=320 output=576\n","I0729 05:31:48.768566 140213217529856 efficientnet_model.py:143] round_filter input=1280 output=2304\n","I0729 05:31:48.908240 140213217529856 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0729 05:31:49.096653 140213217529856 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b7\n","I0729 05:31:49.096846 140213217529856 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 384\n","I0729 05:31:49.096917 140213217529856 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 8\n","I0729 05:31:49.099840 140213217529856 efficientnet_model.py:143] round_filter input=32 output=64\n","I0729 05:31:49.128545 140213217529856 efficientnet_model.py:143] round_filter input=32 output=64\n","I0729 05:31:49.128683 140213217529856 efficientnet_model.py:143] round_filter input=16 output=32\n","I0729 05:31:49.541199 140213217529856 efficientnet_model.py:143] round_filter input=16 output=32\n","I0729 05:31:49.541404 140213217529856 efficientnet_model.py:143] round_filter input=24 output=48\n","I0729 05:31:50.495699 140213217529856 efficientnet_model.py:143] round_filter input=24 output=48\n","I0729 05:31:50.495902 140213217529856 efficientnet_model.py:143] round_filter input=40 output=80\n","I0729 05:31:52.596397 140213217529856 efficientnet_model.py:143] round_filter input=40 output=80\n","I0729 05:31:52.596756 140213217529856 efficientnet_model.py:143] round_filter input=80 output=160\n","I0729 05:31:56.012811 140213217529856 efficientnet_model.py:143] round_filter input=80 output=160\n","I0729 05:31:56.013018 140213217529856 efficientnet_model.py:143] round_filter input=112 output=224\n","I0729 05:31:58.094461 140213217529856 efficientnet_model.py:143] round_filter input=112 output=224\n","I0729 05:31:58.094668 140213217529856 efficientnet_model.py:143] round_filter input=192 output=384\n","I0729 05:31:59.879898 140213217529856 efficientnet_model.py:143] round_filter input=192 output=384\n","I0729 05:31:59.880105 140213217529856 efficientnet_model.py:143] round_filter input=320 output=640\n","I0729 05:32:00.332166 140213217529856 efficientnet_model.py:143] round_filter input=1280 output=2560\n","I0729 05:32:00.371683 140213217529856 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 40.2s\n","I0729 05:32:00.491750 140213217529856 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 40.2s\n","[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n","I0729 05:32:00.519312 140213217529856 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n","I0729 05:32:00.520947 140213217529856 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n","I0729 05:32:00.521478 140213217529856 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n","I0729 05:32:00.522880 140213217529856 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n","[ RUN      ] ModelBuilderTF2Test.test_session\n","[  SKIPPED ] ModelBuilderTF2Test.test_session\n","[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n","I0729 05:32:00.524118 140213217529856 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n","[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n","I0729 05:32:00.524536 140213217529856 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n","[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n","I0729 05:32:00.525493 140213217529856 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n","----------------------------------------------------------------------\n","Ran 24 tests in 47.009s\n","\n","OK (skipped=1)\n"]}]},{"cell_type":"code","metadata":{"id":"m1UT5_rrTw6e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690609441094,"user_tz":-480,"elapsed":389,"user":{"displayName":"r3xSean","userId":"17171356728383377491"}},"outputId":"c52eb3ef-a9b0-40dd-fd5e-966f0aa332c9"},"source":["%cd /mydrive/customTF2/data/"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/My Drive/customTF2/data\n"]}]},{"cell_type":"markdown","metadata":{"id":"vH67M2M12s3n"},"source":["## Create the CSV files and the \"label_map.pbtxt\" file\n","\n","The xml_to_csv script creates the CSVs, ***test_labels.csv*** and ***train_labels.csv***, make sure to run it\n","\n","This also creates the ***label_map.pbtxt*** file using the classes mentioned in the xml files."]},{"cell_type":"code","metadata":{"id":"VyGisGxK4ag0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690603509116,"user_tz":-480,"elapsed":644,"user":{"displayName":"r3xSean","userId":"17171356728383377491"}},"outputId":"34956a92-045b-43ac-ff46-821971546370"},"source":["# used from xml to csv from https://github.com/techzizou/Train-Object-Detection-Model-TF-2.x\n","def xml_to_csv(path):\n","  classes_names = []\n","  xml_list = []\n","\n","  for xml_file in glob.glob(path + '/*.xml'):\n","    tree = ET.parse(xml_file)\n","    root = tree.getroot()\n","    for member in root.findall('object'):\n","      classes_names.append(member[0].text)\n","      value = (root.find('filename').text  ,\n","               int(root.find('size')[0].text),\n","               int(root.find('size')[1].text),\n","               member[0].text,\n","               int(member[4][0].text),\n","               int(member[4][1].text),\n","               int(member[4][2].text),\n","               int(member[4][3].text))\n","      xml_list.append(value)\n","  column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n","  xml_df = pd.DataFrame(xml_list, columns=column_name)\n","  classes_names = list(set(classes_names))\n","  classes_names.sort()\n","  return xml_df, classes_names\n","\n","for label_path in ['train_labels', 'test_labels']:\n","  image_path = os.path.join(os.getcwd(), label_path)\n","  xml_df, classes = xml_to_csv(label_path)\n","  xml_df.to_csv(f'{label_path}.csv', index=None)\n","  print(f'Successfully converted {label_path} xml to csv.')\n","\n","label_map_path = os.path.join(\"label_map.pbtxt\")\n","pbtxt_content = \"\"\n","\n","for i, class_name in enumerate(classes):\n","    pbtxt_content = (\n","        pbtxt_content\n","        + \"item {{\\n    id: {0}\\n    name: '{1}'\\n}}\\n\\n\".format(i + 1, class_name)\n","    )\n","pbtxt_content = pbtxt_content.strip()\n","with open(label_map_path, \"w\") as f:\n","    f.write(pbtxt_content)\n","    print('Successfully created label_map.pbtxt ')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Successfully converted train_labels xml to csv.\n","Successfully converted test_labels xml to csv.\n","Successfully created label_map.pbtxt \n"]}]},{"cell_type":"code","metadata":{"id":"ET4SXdtYUIjZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690603566285,"user_tz":-480,"elapsed":51983,"user":{"displayName":"r3xSean","userId":"17171356728383377491"}},"outputId":"7af59310-ccc3-4d75-91b5-50b10815c148"},"source":["!python /mydrive/customTF2/generate_tfrecord.py train_labels.csv  label_map.pbtxt images/ train.record\n","!python /mydrive/customTF2/generate_tfrecord.py test_labels.csv  label_map.pbtxt images/ test.record"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-07-29 04:05:17.959410: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","groups: 100% 132/132 [00:34<00:00,  3.83it/s]\n","Successfully created the TFRecords: /content/gdrive/MyDrive/customTF2/data/train.record\n","2023-07-29 04:05:57.350963: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","groups: 100% 33/33 [00:08<00:00,  3.83it/s]\n","Successfully created the TFRecords: /content/gdrive/My Drive/customTF2/data/test.record\n"]}]},{"cell_type":"markdown","source":["## Download pre-trained model checkpoint\n","\n","Download **ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz** into the ***data*** folder & unzip it.\n","\n","A list of detection checkpoints for tensorflow 2.x can be found [here](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md).\n","\n"],"metadata":{"id":"twUp7TQWK9ks"}},{"cell_type":"code","source":["!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n","!tar -xzvf ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AKHzl5W0K-R-","executionInfo":{"status":"ok","timestamp":1690609445912,"user_tz":-480,"elapsed":1546,"user":{"displayName":"r3xSean","userId":"17171356728383377491"}},"outputId":"19f75722-f66f-4669-81a2-295bd669960a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-07-29 05:44:06--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n","Resolving download.tensorflow.org (download.tensorflow.org)... 173.194.202.128, 2607:f8b0:400e:c00::80\n","Connecting to download.tensorflow.org (download.tensorflow.org)|173.194.202.128|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 20515344 (20M) [application/x-tar]\n","Saving to: ‘ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz’\n","\n","ssd_mobilenet_v2_fp 100%[===================>]  19.56M  75.2MB/s    in 0.3s    \n","\n","2023-07-29 05:44:06 (75.2 MB/s) - ‘ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz’ saved [20515344/20515344]\n","\n","ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/\n","ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/\n","ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n","ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/checkpoint\n","ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.index\n","ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config\n","ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/\n","ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/saved_model.pb\n","ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/\n","ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n","ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.index\n"]}]},{"cell_type":"markdown","metadata":{"id":"XS-xqg02X9Ro"},"source":["## Get the model pipeline config file, make changes to it and put it inside the ***data*** folder\n","\n","Downloaded **ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.config** from ***/content/models/research/object_detection/configs/tf2*** and uploaded it to the ***/mydrive/custom/data*** folder.\n","\n","Changes needed: num_classes, all PATHs, fine_tune_checkpoint, fine_tune_checkpoint_type, batch_size, num_steps\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"88pz7JpMNRRK"},"source":["## Load Tensorboard *"]},{"cell_type":"code","metadata":{"id":"l-86d0AXNQp7","colab":{"base_uri":"https://localhost:8080/","height":225},"executionInfo":{"status":"ok","timestamp":1690608906785,"user_tz":-480,"elapsed":6522,"user":{"displayName":"r3xSean","userId":"17171356728383377491"}},"outputId":"76032941-7a01-4b41-ffc2-2887ed8b0880"},"source":["#load tensorboard\n","\n","%load_ext tensorboard\n","%tensorboard --logdir '/content/gdrive/MyDrive/customTF2/training'"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The tensorboard extension is already loaded. To reload it, use:\n","  %reload_ext tensorboard\n"]},{"output_type":"display_data","data":{"text/plain":["ERROR: Failed to launch TensorBoard (exited with 1).\n","Contents of stderr:\n","2023-07-29 05:35:04.631751: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\n","NOTE: Using experimental fast data loading logic. To disable, pass\n","    \"--load_fast=false\" and report issues on GitHub. More details:\n","    https://github.com/tensorflow/tensorboard/issues/4784\n","\n","Address already in use\n","Port 6006 is in use by another program. Either identify and stop that program, or start the server with a different port."]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"tlzGrIfdAKj9"},"source":["## Train the model *\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"-40iq_0ZMgfL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690609605523,"user_tz":-480,"elapsed":413,"user":{"displayName":"r3xSean","userId":"17171356728383377491"}},"outputId":"a2af6cc6-015c-45e5-b5eb-1f5a1e6ca0fe"},"source":["%cd /content/models/research/object_detection"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/models/research/object_detection\n"]}]},{"cell_type":"markdown","metadata":{"id":"_pjP3TuBMjli"},"source":["###Training"]},{"cell_type":"code","metadata":{"id":"7LS0SBCgRuox","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690612546267,"user_tz":-480,"elapsed":2792635,"user":{"displayName":"r3xSean","userId":"17171356728383377491"}},"outputId":"f51bdca7-eb70-4b5e-ea9e-075d07dda039"},"source":["!python model_main_tf2.py --pipeline_config_path=/mydrive/customTF2/data/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.config --model_dir=/mydrive/customTF2/training --alsologtostderr"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-07-29 05:49:17.147179: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","/usr/local/lib/python3.10/dist-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/usr/local/lib/python3.10/dist-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n","caused by: ['/usr/local/lib/python3.10/dist-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6Status12empty_stringB5cxx11Ev']\n","  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n","/usr/local/lib/python3.10/dist-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/usr/local/lib/python3.10/dist-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n","caused by: ['/usr/local/lib/python3.10/dist-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZNK10tensorflow4data11DatasetBase8FinalizeEPNS_15OpKernelContextESt8functionIFN3tsl8StatusOrISt10unique_ptrIS1_NS5_4core15RefCountDeleterEEEEvEE']\n","  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","2023-07-29 05:49:22.401398: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n","I0729 05:49:22.402791 137824039321600 mirrored_strategy.py:419] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n","INFO:tensorflow:Maybe overwriting train_steps: None\n","I0729 05:49:22.756144 137824039321600 config_util.py:552] Maybe overwriting train_steps: None\n","INFO:tensorflow:Maybe overwriting use_bfloat16: False\n","I0729 05:49:22.756409 137824039321600 config_util.py:552] Maybe overwriting use_bfloat16: False\n","WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","rename to distribute_datasets_from_function\n","W0729 05:49:23.000766 137824039321600 deprecation.py:364] From /usr/local/lib/python3.10/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","rename to distribute_datasets_from_function\n","INFO:tensorflow:Reading unweighted datasets: ['/content/gdrive/MyDrive/customTF2/data/train.record']\n","I0729 05:49:23.015828 137824039321600 dataset_builder.py:162] Reading unweighted datasets: ['/content/gdrive/MyDrive/customTF2/data/train.record']\n","INFO:tensorflow:Reading record datasets for input file: ['/content/gdrive/MyDrive/customTF2/data/train.record']\n","I0729 05:49:23.016218 137824039321600 dataset_builder.py:79] Reading record datasets for input file: ['/content/gdrive/MyDrive/customTF2/data/train.record']\n","INFO:tensorflow:Number of filenames to read: 1\n","I0729 05:49:23.016366 137824039321600 dataset_builder.py:80] Number of filenames to read: 1\n","WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n","W0729 05:49:23.016453 137824039321600 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\n","WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n","W0729 05:49:23.026039 137824039321600 deprecation.py:364] From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n","WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","W0729 05:49:23.058276 137824039321600 deprecation.py:364] From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","W0729 05:49:32.946435 137824039321600 deprecation.py:364] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1176: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n","W0729 05:49:35.544035 137824039321600 deprecation.py:364] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1176: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W0729 05:49:37.091062 137824039321600 deprecation.py:364] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","2023-07-29 05:49:50.688996: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 471859200 exceeds 10% of free system memory.\n","2023-07-29 05:49:54.975238: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 471859200 exceeds 10% of free system memory.\n","2023-07-29 05:49:55.287940: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 412640280 exceeds 10% of free system memory.\n","2023-07-29 05:49:55.441190: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 471859200 exceeds 10% of free system memory.\n","2023-07-29 05:49:55.809025: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 412640280 exceeds 10% of free system memory.\n","/usr/local/lib/python3.10/dist-packages/keras/src/backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n","  warnings.warn(\n","I0729 05:50:11.257375 137819153483328 api.py:460] feature_map_spatial_dims: [(40, 40), (20, 20), (10, 10), (5, 5), (3, 3)]\n","I0729 05:50:26.904533 137819153483328 api.py:460] feature_map_spatial_dims: [(40, 40), (20, 20), (10, 10), (5, 5), (3, 3)]\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0729 05:50:45.873946 137824039321600 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0729 05:50:45.876768 137824039321600 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0729 05:50:45.877848 137824039321600 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0729 05:50:45.878846 137824039321600 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0729 05:50:45.883743 137824039321600 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0729 05:50:45.885070 137824039321600 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0729 05:50:45.886150 137824039321600 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0729 05:50:45.887107 137824039321600 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0729 05:50:45.891705 137824039321600 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0729 05:50:45.892694 137824039321600 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/deprecation.py:648: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use fn_output_signature instead\n","W0729 05:50:47.149163 137819175507520 deprecation.py:569] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/deprecation.py:648: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use fn_output_signature instead\n","I0729 05:50:48.226697 137819175507520 api.py:460] feature_map_spatial_dims: [(40, 40), (20, 20), (10, 10), (5, 5), (3, 3)]\n","I0729 05:51:04.184680 137819175507520 api.py:460] feature_map_spatial_dims: [(40, 40), (20, 20), (10, 10), (5, 5), (3, 3)]\n","I0729 05:51:16.423157 137819175507520 api.py:460] feature_map_spatial_dims: [(40, 40), (20, 20), (10, 10), (5, 5), (3, 3)]\n","I0729 05:51:30.279283 137819175507520 api.py:460] feature_map_spatial_dims: [(40, 40), (20, 20), (10, 10), (5, 5), (3, 3)]\n","INFO:tensorflow:Step 100 per-step time 2.974s\n","I0729 05:55:44.463201 137824039321600 model_lib_v2.py:705] Step 100 per-step time 2.974s\n","INFO:tensorflow:{'Loss/classification_loss': 0.19582644,\n"," 'Loss/localization_loss': 0.1601019,\n"," 'Loss/regularization_loss': 0.15342706,\n"," 'Loss/total_loss': 0.5093554,\n"," 'learning_rate': 0.0319994}\n","I0729 05:55:44.466037 137824039321600 model_lib_v2.py:708] {'Loss/classification_loss': 0.19582644,\n"," 'Loss/localization_loss': 0.1601019,\n"," 'Loss/regularization_loss': 0.15342706,\n"," 'Loss/total_loss': 0.5093554,\n"," 'learning_rate': 0.0319994}\n","INFO:tensorflow:Step 200 per-step time 2.189s\n","I0729 05:59:23.202781 137824039321600 model_lib_v2.py:705] Step 200 per-step time 2.189s\n","INFO:tensorflow:{'Loss/classification_loss': 0.11000679,\n"," 'Loss/localization_loss': 0.082194574,\n"," 'Loss/regularization_loss': 0.15316433,\n"," 'Loss/total_loss': 0.3453657,\n"," 'learning_rate': 0.0373328}\n","I0729 05:59:23.203252 137824039321600 model_lib_v2.py:708] {'Loss/classification_loss': 0.11000679,\n"," 'Loss/localization_loss': 0.082194574,\n"," 'Loss/regularization_loss': 0.15316433,\n"," 'Loss/total_loss': 0.3453657,\n"," 'learning_rate': 0.0373328}\n","INFO:tensorflow:Step 300 per-step time 1.883s\n","I0729 06:02:31.629597 137824039321600 model_lib_v2.py:705] Step 300 per-step time 1.883s\n","INFO:tensorflow:{'Loss/classification_loss': 0.10874227,\n"," 'Loss/localization_loss': 0.054337505,\n"," 'Loss/regularization_loss': 0.15279634,\n"," 'Loss/total_loss': 0.31587613,\n"," 'learning_rate': 0.0426662}\n","I0729 06:02:31.631372 137824039321600 model_lib_v2.py:708] {'Loss/classification_loss': 0.10874227,\n"," 'Loss/localization_loss': 0.054337505,\n"," 'Loss/regularization_loss': 0.15279634,\n"," 'Loss/total_loss': 0.31587613,\n"," 'learning_rate': 0.0426662}\n","INFO:tensorflow:Step 400 per-step time 2.124s\n","I0729 06:06:03.879251 137824039321600 model_lib_v2.py:705] Step 400 per-step time 2.124s\n","INFO:tensorflow:{'Loss/classification_loss': 0.09637254,\n"," 'Loss/localization_loss': 0.07460134,\n"," 'Loss/regularization_loss': 0.15237269,\n"," 'Loss/total_loss': 0.32334656,\n"," 'learning_rate': 0.047999598}\n","I0729 06:06:03.879696 137824039321600 model_lib_v2.py:708] {'Loss/classification_loss': 0.09637254,\n"," 'Loss/localization_loss': 0.07460134,\n"," 'Loss/regularization_loss': 0.15237269,\n"," 'Loss/total_loss': 0.32334656,\n"," 'learning_rate': 0.047999598}\n","INFO:tensorflow:Step 500 per-step time 2.134s\n","I0729 06:09:37.250893 137824039321600 model_lib_v2.py:705] Step 500 per-step time 2.134s\n","INFO:tensorflow:{'Loss/classification_loss': 0.0981369,\n"," 'Loss/localization_loss': 0.051852386,\n"," 'Loss/regularization_loss': 0.15188724,\n"," 'Loss/total_loss': 0.30187654,\n"," 'learning_rate': 0.053333}\n","I0729 06:09:37.251425 137824039321600 model_lib_v2.py:708] {'Loss/classification_loss': 0.0981369,\n"," 'Loss/localization_loss': 0.051852386,\n"," 'Loss/regularization_loss': 0.15188724,\n"," 'Loss/total_loss': 0.30187654,\n"," 'learning_rate': 0.053333}\n","INFO:tensorflow:Step 600 per-step time 1.871s\n","I0729 06:12:44.348385 137824039321600 model_lib_v2.py:705] Step 600 per-step time 1.871s\n","INFO:tensorflow:{'Loss/classification_loss': 0.07258468,\n"," 'Loss/localization_loss': 0.041209336,\n"," 'Loss/regularization_loss': 0.15135248,\n"," 'Loss/total_loss': 0.2651465,\n"," 'learning_rate': 0.0586664}\n","I0729 06:12:44.355648 137824039321600 model_lib_v2.py:708] {'Loss/classification_loss': 0.07258468,\n"," 'Loss/localization_loss': 0.041209336,\n"," 'Loss/regularization_loss': 0.15135248,\n"," 'Loss/total_loss': 0.2651465,\n"," 'learning_rate': 0.0586664}\n","INFO:tensorflow:Step 700 per-step time 2.085s\n","I0729 06:16:12.812742 137824039321600 model_lib_v2.py:705] Step 700 per-step time 2.085s\n","INFO:tensorflow:{'Loss/classification_loss': 0.06048615,\n"," 'Loss/localization_loss': 0.035372917,\n"," 'Loss/regularization_loss': 0.15075055,\n"," 'Loss/total_loss': 0.24660961,\n"," 'learning_rate': 0.0639998}\n","I0729 06:16:12.813191 137824039321600 model_lib_v2.py:708] {'Loss/classification_loss': 0.06048615,\n"," 'Loss/localization_loss': 0.035372917,\n"," 'Loss/regularization_loss': 0.15075055,\n"," 'Loss/total_loss': 0.24660961,\n"," 'learning_rate': 0.0639998}\n","INFO:tensorflow:Step 800 per-step time 2.013s\n","I0729 06:19:34.158174 137824039321600 model_lib_v2.py:705] Step 800 per-step time 2.013s\n","INFO:tensorflow:{'Loss/classification_loss': 0.064007714,\n"," 'Loss/localization_loss': 0.029097283,\n"," 'Loss/regularization_loss': 0.15009862,\n"," 'Loss/total_loss': 0.24320361,\n"," 'learning_rate': 0.069333196}\n","I0729 06:19:34.162753 137824039321600 model_lib_v2.py:708] {'Loss/classification_loss': 0.064007714,\n"," 'Loss/localization_loss': 0.029097283,\n"," 'Loss/regularization_loss': 0.15009862,\n"," 'Loss/total_loss': 0.24320361,\n"," 'learning_rate': 0.069333196}\n","INFO:tensorflow:Step 900 per-step time 1.983s\n","I0729 06:22:52.381082 137824039321600 model_lib_v2.py:705] Step 900 per-step time 1.983s\n","INFO:tensorflow:{'Loss/classification_loss': 0.06342594,\n"," 'Loss/localization_loss': 0.031713713,\n"," 'Loss/regularization_loss': 0.14939418,\n"," 'Loss/total_loss': 0.24453384,\n"," 'learning_rate': 0.074666604}\n","I0729 06:22:52.381562 137824039321600 model_lib_v2.py:708] {'Loss/classification_loss': 0.06342594,\n"," 'Loss/localization_loss': 0.031713713,\n"," 'Loss/regularization_loss': 0.14939418,\n"," 'Loss/total_loss': 0.24453384,\n"," 'learning_rate': 0.074666604}\n","INFO:tensorflow:Step 1000 per-step time 2.021s\n","I0729 06:26:14.529410 137824039321600 model_lib_v2.py:705] Step 1000 per-step time 2.021s\n","INFO:tensorflow:{'Loss/classification_loss': 0.058723442,\n"," 'Loss/localization_loss': 0.031290825,\n"," 'Loss/regularization_loss': 0.14864361,\n"," 'Loss/total_loss': 0.23865788,\n"," 'learning_rate': 0.08}\n","I0729 06:26:14.529923 137824039321600 model_lib_v2.py:708] {'Loss/classification_loss': 0.058723442,\n"," 'Loss/localization_loss': 0.031290825,\n"," 'Loss/regularization_loss': 0.14864361,\n"," 'Loss/total_loss': 0.23865788,\n"," 'learning_rate': 0.08}\n","INFO:tensorflow:Step 1100 per-step time 2.036s\n","I0729 06:29:38.122544 137824039321600 model_lib_v2.py:705] Step 1100 per-step time 2.036s\n","INFO:tensorflow:{'Loss/classification_loss': 0.06839132,\n"," 'Loss/localization_loss': 0.02457066,\n"," 'Loss/regularization_loss': 0.14785674,\n"," 'Loss/total_loss': 0.24081872,\n"," 'learning_rate': 0.07999918}\n","I0729 06:29:38.123389 137824039321600 model_lib_v2.py:708] {'Loss/classification_loss': 0.06839132,\n"," 'Loss/localization_loss': 0.02457066,\n"," 'Loss/regularization_loss': 0.14785674,\n"," 'Loss/total_loss': 0.24081872,\n"," 'learning_rate': 0.07999918}\n","INFO:tensorflow:Step 1200 per-step time 2.008s\n","I0729 06:32:58.877884 137824039321600 model_lib_v2.py:705] Step 1200 per-step time 2.008s\n","INFO:tensorflow:{'Loss/classification_loss': 0.058379803,\n"," 'Loss/localization_loss': 0.023696417,\n"," 'Loss/regularization_loss': 0.14706914,\n"," 'Loss/total_loss': 0.22914536,\n"," 'learning_rate': 0.079996705}\n","I0729 06:32:58.878391 137824039321600 model_lib_v2.py:708] {'Loss/classification_loss': 0.058379803,\n"," 'Loss/localization_loss': 0.023696417,\n"," 'Loss/regularization_loss': 0.14706914,\n"," 'Loss/total_loss': 0.22914536,\n"," 'learning_rate': 0.079996705}\n","^C\n"]}]},{"cell_type":"code","source":["#plotting the graph of loss Vs Steps\n","import matplotlib.pyplot as plt\n","\n","loss = [0.5,0.34,0.31,0.32,0.3,0.26,0.24,0.24,0.23,0.24,0.23,0.22]\n","steps = [100,200,300,400,500,600,700,800,900,1000,1100,1200]\n","\n","plt.plot(steps,loss)\n","plt.title(\"Loss vs Steps\")\n","plt.xlabel(\"Steps\")\n","plt.ylabel(\"Loss\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":489},"id":"X9yhA0uWgns8","executionInfo":{"status":"ok","timestamp":1690615272841,"user_tz":-480,"elapsed":415,"user":{"displayName":"r3xSean","userId":"17171356728383377491"}},"outputId":"51b248a4-dcd8-4214-9e70-45f600aeabd4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Text(0, 0.5, 'Loss')"]},"metadata":{},"execution_count":39},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"NB4JHHqHSoiq"},"source":["##Export inference graph\n","!python exporter_main_v2.py --trained_checkpoint_dir=/mydrive/customTF2/training --pipeline_config_path=/content/gdrive/MyDrive/customTF2/data/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.config --output_directory /mydrive/customTF2/data/inference_graph"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Using our trained alien detection model"],"metadata":{"id":"D2oOhnvYfIHs"}},{"cell_type":"markdown","source":["## Download [this](https://github.com/r3xsean/alien_detection/blob/main/inference_graph-20230729T070618Z-001.zip) and unzip in data folder, also download [this](https://github.com/r3xsean/alien_detection/blob/main/label_map.pbtxt) and put inside data folder"],"metadata":{"id":"qnNSgw-6fK87"}},{"cell_type":"markdown","metadata":{"id":"Nxn-FtdtpsTx"},"source":["# Using the model"]},{"cell_type":"code","source":["%cd /content/models/research/object_detection"],"metadata":{"id":"tXjMv-UpvpCU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Find the image_path line and change it to the path of your image, then run the file!"],"metadata":{"id":"oEgSPS49jdVd"}},{"cell_type":"code","metadata":{"id":"6Iq2Wq3SKtOs"},"source":["#Loading the saved_model\n","import tensorflow as tf\n","import time\n","import numpy as np\n","import warnings\n","warnings.filterwarnings('ignore')\n","from PIL import Image\n","from google.colab.patches import cv2_imshow\n","from object_detection.utils import label_map_util\n","from object_detection.utils import visualization_utils as viz_utils # imports the utils needed for visualization of the the image and box containing the class\n","\n","IMAGE_SIZE = (15, 15) # how big the image is\n","import matplotlib.pyplot as plt\n","PATH_TO_SAVED_MODEL=\"/mydrive/customTF2/data/inference_graph/saved_model\"\n","\n","print('Model is loading!')\n","detect_fn=tf.saved_model.load(PATH_TO_SAVED_MODEL) # loads the model\n","print('Complete!')\n","\n","# loads the label map (contains the classes)\n","category_index=label_map_util.create_category_index_from_labelmap(\"/mydrive/customTF2/data/label_map.pbtxt\",use_display_name=True)\n","\n","\n","image_path = \"/mydrive/alien_test.jpg\" # IMAGE PATH IMAGE PATH IMAGE PATH\n","\n","def load_image_into_array(pth):\n","    return np.array(Image.open(pth))\n","\n","image_np = load_image_into_array(image_path) # loads the image into numpy array\n","\n","# input has to be tensor, so convert it to\n","input_tensor = tf.convert_to_tensor(image_np)\n","# batch expected, so add an axis\n","input_tensor = input_tensor[tf.newaxis, ...]\n","\n","detections = detect_fn(input_tensor)\n","\n","num_detections = int(detections.pop('num_detections')) #num detections has to be an integer\n","detections = {key: value[0, :num_detections].numpy()\n","              for key, value in detections.items()}\n","detections['num_detections'] = num_detections\n","\n","detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n","\n","image_np_with_detections = image_np.copy()\n","\n","viz_utils.visualize_boxes_and_labels_on_image_array(\n","      image_np_with_detections,\n","      detections['detection_boxes'],\n","      detections['detection_classes'],\n","      detections['detection_scores'],\n","      category_index,\n","      use_normalized_coordinates=True,\n","      max_boxes_to_draw=200,\n","      min_score_thresh=.4, # min probability of box being correct\n","      agnostic_mode=False)\n","%matplotlib inline\n","plt.figure(figsize=IMAGE_SIZE, dpi=200)\n","plt.axis(\"off\")\n","plt.imshow(image_np_with_detections)\n","plt.show()"],"execution_count":null,"outputs":[]}]}